{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a literature review on the topic 'Advance features on Earbuds or Airpods within last 2 years'. You can search for some relevant keywords on google, you can find the publications in arxiv archives too if required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for Google_Search_Agent/3eb19c67-a23b-4ebe-a1cd-a7eaa06523a1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py\", line 505, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_base_agent.py\", line 113, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 48, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 53, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 416, in on_messages_stream\n",
      "    model_result = await self._model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py\", line 534, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1856, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1550, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1636, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1683, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1636, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1683, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1651, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content=\"Write a literature review on the topic 'Advance features on Earbuds or Airpods within last 2 years'. You can search for some relevant keywords on google, you can find the publications in arxiv archives too if required.\", type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "import os\n",
    "import time\n",
    "import markdown2\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    \n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
    "\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": api_key, \"cx\": search_engine_id, \"q\": query, \"num\": num_results}\n",
    "\n",
    "    response = requests.get(url, params=params)  # type: ignore[arg-type]\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results\n",
    "\n",
    "\n",
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # # Write results to a file\n",
    "    # with open('arxiv_search_results.json', 'w') as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_pdf(content: str, filename: str = \"output.pdf\", output_dir: str = \"output\") -> str:\n",
    "    \"\"\"Generate a PDF file from text content with proper word wrapping and markdown support.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Ensure the filename has a .pdf extension\n",
    "    if not filename.lower().endswith(\".pdf\"):\n",
    "        filename += \".pdf\"\n",
    "\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Convert Markdown to HTML\n",
    "    html_content = markdown2.markdown(content)\n",
    "\n",
    "    # Create a PDF document\n",
    "    doc = SimpleDocTemplate(filepath, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "\n",
    "    # Convert HTML to ReportLab Paragraph\n",
    "    for paragraph in html_content.split(\"\\n\"):\n",
    "        if paragraph.strip():  # Ignore empty lines\n",
    "            story.append(Paragraph(paragraph, styles[\"Normal\"]))\n",
    "            story.append(Spacer(1, 12))  # Add spacing between paragraphs\n",
    "\n",
    "    # Build the PDF\n",
    "    doc.build(story)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "google_search_tool = FunctionTool(\n",
    "    google_search,\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for information, returning results with snippets and body content.\"\n",
    ")\n",
    "\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search,\n",
    "    name=\"arxiv_search\",\n",
    "    description=\"Search Arxiv for papers related to a given topic, including abstracts.\"\n",
    ")\n",
    "\n",
    "pdf_generator_tool = FunctionTool(\n",
    "    generate_pdf,\n",
    "    name=\"pdf_generator\",\n",
    "    description=\"Generate a PDF document from given content and save it in the output folder with markdown support.\"\n",
    ")\n",
    "\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-1.5-pro\",  # Ensure this model supports the required features\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    api_type=\"google\",\n",
    "    model_info={\n",
    "        \"vision\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=model_client,\n",
    "    description=\"An agent that searches Google for information, returning results with snippets and body content.\",\n",
    "    system_message=\"You are a helpful AI assistant. Use the provided tools to retrieve and present information effectively.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=model_client,\n",
    "    description=\"An agent that searches Arxiv for academic papers related to a given topic, including abstracts.\",\n",
    "    system_message=\"You are a helpful AI assistant. Utilize the provided tools to find and summarize academic papers relevant to the user's query.\",\n",
    ")\n",
    "\n",
    "report_agent_gemini = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=model_client,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    tools=[pdf_generator_tool],\n",
    "    system_message=(\n",
    "        \"You are a helpful assistant. Your task is to synthesize data extracted into a high-quality \"\n",
    "        \"literature review including CORRECT references. You MUST write a final report that is formatted \"\n",
    "        \"as a literature review with CORRECT references. Use the pdf_generator_tool to save the report as pdf file \"\n",
    "        \"Your response should end with the word 'TERMINATE'.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "termination_condition = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent_gemini],\n",
    "    termination_condition=termination_condition\n",
    ")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(\n",
    "    team.run_stream(\n",
    "        task=\"Write a literature review on the topic 'Advance features on Earbuds or Airpods within last 2 years'. You can search for some relevant keywords on google, you can find the publications in arxiv archives too if required.\",\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

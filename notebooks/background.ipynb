{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some required prior steps\n",
    "\n",
    "1. Create a new credential API_KEY or use existing one from https://console.cloud.google.com/apis/credentials . Add the key under GOOGLE_API_KEY in environment or through dotenv utilities\n",
    "\n",
    "2. Create a new search engine id or use existing one from https://programmablesearchengine.google.com/controlpanel/all . Add the key under GOOGLE_SEARCH_ENGINE_ID in environment or through dotenv utilities\n",
    "\n",
    "3. Add your OpenAI API key under OPENAI_API_KEY key in environment or through dotenv utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a literature review on no code tools for building multi agent ai systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for Google_Search_Agent/272b865c-c141-475d-bfa9-01383d2ab3c0\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py\", line 505, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_base_agent.py\", line 113, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 48, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 53, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 416, in on_messages_stream\n",
      "    model_result = await self._model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py\", line 534, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1856, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1550, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1636, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1683, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1636, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1683, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1651, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Write a literature review on no code tools for building multi agent ai systems', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    \n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
    "\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": api_key, \"cx\": search_engine_id, \"q\": query, \"num\": num_results}\n",
    "\n",
    "    response = requests.get(url, params=params)  # type: ignore[arg-type]\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results\n",
    "\n",
    "\n",
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # # Write results to a file\n",
    "    # with open('arxiv_search_results.json', 'w') as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
    ")\n",
    "\n",
    "\n",
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
    ")\n",
    "\n",
    "\n",
    "# OpenAI\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")\n",
    "\n",
    "# Local Ollama\n",
    "\n",
    "def get_model_client_local():\n",
    "    return OpenAIChatCompletionClient(\n",
    "        model=\"llama3.2:1b\",\n",
    "        api_key=\"NotRequiredSinceWeAreLocal\",\n",
    "        base_url=\"http://http://0.0.0.0:11434\",\n",
    "        model_capabilities={\n",
    "            \"json_output\": False,\n",
    "            \"vision\": False,\n",
    "            \"function_calling\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "# Gemini\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "        #model=\"gemini-1.5-flash\",\n",
    "        model='gemini-pro',\n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "        model_info={\n",
    "            \"vision\": True,\n",
    "            \"function_calling\": True,\n",
    "            \"json_output\": True,\n",
    "            \"family\": \"unknown\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "report_agent_gemini = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=model_client,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")\n",
    "\n",
    "report_agent_ollama = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=get_model_client_local,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")\n",
    "\n",
    "\n",
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent_ollama], termination_condition=termination\n",
    ")\n",
    "\n",
    "await Console(\n",
    "    team.run_stream(\n",
    "        task=\"Write a literature review on no code tools for building multi agent ai systems\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

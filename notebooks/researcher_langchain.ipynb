{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import Tool, create_react_agent, AgentExecutor\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.utilities import ArxivAPIWrapper\n",
    "from langchain_experimental.utilities.python import PythonREPL\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys and project details from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GOOGLE_CLOUD_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "GOOGLE_CLOUD_PROJECT_LOCATION = os.getenv(\"GOOGLE_CLOUD_PROJECT_LOCATION\")\n",
    "\n",
    "# Flag to choose between Gemini and OpenAI models\n",
    "use_gemini = True\n",
    "\n",
    "# Initialize the language model (LLM) based on the chosen provider\n",
    "if use_gemini:\n",
    "    import vertexai\n",
    "    from google.auth import default\n",
    "\n",
    "    # Initialize Vertex AI with the specified project and location\n",
    "    credentials, project = default()\n",
    "    vertexai.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_PROJECT_LOCATION)\n",
    "\n",
    "    # Create a ChatVertexAI instance with the specified model and temperature\n",
    "    llm = ChatVertexAI(\n",
    "        model_name=\"gemini-1.5-pro\",\n",
    "        temperature=0.2,\n",
    "        google_api_key=GEMINI_API_KEY\n",
    "    )\n",
    "else:\n",
    "    # Create a ChatOpenAI instance with the specified model and temperature\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "# Initialize the Arxiv API wrapper\n",
    "arxiv = ArxivAPIWrapper()\n",
    "\n",
    "# Define a custom tool for searching papers on ArXiv\n",
    "class ArxivSearchTool(BaseTool):\n",
    "    name: str = \"arxiv_search\"\n",
    "    description: str = \"Search for papers on ArXiv by topic.\"\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        try:\n",
    "            # Run the Arxiv API wrapper with the given query\n",
    "            results = arxiv.run(query)\n",
    "            # Split the results into individual papers\n",
    "            papers = [p.strip() for p in results.split(\"\\n\\n\") if p.strip()]\n",
    "            # Format the results into a markdown string\n",
    "            formatted = \"# ArXiv Search Results\\n\\n\"\n",
    "            for i, p in enumerate(papers, start=1):\n",
    "                formatted += f\"## Paper {i}\\n{p}\\n\\n\"\n",
    "            return formatted\n",
    "        except Exception as e:\n",
    "            # Return an error message if the search fails\n",
    "            return f\"Error searching ArXiv: {str(e)}\"\n",
    "    \n",
    "    async def _arun(self, query: str):\n",
    "        # Asynchronous version is not implemented\n",
    "        raise NotImplementedError(\"Async not implemented\")\n",
    "\n",
    "# Instantiate the ArxivSearchTool\n",
    "arxiv_tool = ArxivSearchTool()\n",
    "\n",
    "# Initialize the Python REPL tool\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=(\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. If you want to see the output of a value, \"\n",
    "        \"you should print it out with `print(...)`.\"\n",
    "    ),\n",
    "    func=python_repl.run,\n",
    ")\n",
    "\n",
    "# List of tools available to the agent\n",
    "tools = [arxiv_tool, repl_tool]\n",
    "\n",
    "# Initialize conversation memory to keep track of the dialogue history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Define the prompt template with required placeholders\n",
    "template = \"\"\"\n",
    "You are a researcher specialized in analyzing scientific papers.\n",
    "Your tasks are to:\n",
    "1. Search for papers on a given topic using the available tools.\n",
    "2. Analyze the retrieved papers and extract key insights.\n",
    "3. Generate a comprehensive markdown report with these sections:\n",
    "   Introduction, Overview of Papers, Detailed Analysis, and Summary and Conclusions.\n",
    "4. Use the python_repl tool to convert the markdown report into a PDF file.\n",
    "Be concise yet thorough in your analysis.\n",
    "\n",
    "Available tools:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: {input}\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance from the template string\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the ReAct agent using the language model, tools, and prompt\n",
    "researcher_agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Wrap the agent with AgentExecutor to manage its execution\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=researcher_agent, tools=tools, memory=memory, verbose=True\n",
    ")\n",
    "\n",
    "# Function to run the research workflow for a given topic\n",
    "def run_research_workflow(topic: str) -> str:\n",
    "    # Generate the output filename based on the topic\n",
    "    output_filename = f\"{topic.replace(' ', '_')}_review.pdf\"\n",
    "    # Define the prompt for the agent\n",
    "    prompt = (\n",
    "        f\"Generate a comprehensive technical review on the topic '{topic}'. \"\n",
    "        \"Steps: \"\n",
    "        \"1. Use the arxiv_search tool to find recent papers. \"\n",
    "        \"2. Analyze the papers and extract key insights. \"\n",
    "        \"3. Create a markdown report with sections: Introduction, Overview of Papers, Detailed Analysis, and Summary and Conclusions. \"\n",
    "        f\"4. Use the python_repl tool to convert the markdown report to a PDF file named {output_filename}. \"\n",
    "        \"Provide both the markdown report and confirmation of PDF creation in your final output.\"\n",
    "    )\n",
    "    agent_executor.run(prompt)\n",
    "    return output_filename\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"BCG Signal Processing\"\n",
    "    pdf_path = run_research_workflow(topic)\n",
    "    print(f\"Research document should be available at: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 2 + 2?', 'output': '4'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "from langchain_experimental.utilities.python import PythonREPL\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=(\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. If you want to see the output of a value, \"\n",
    "        \"you should print it out with `print(...)`.\"\n",
    "    ),\n",
    "    func=python_repl.run,\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[repl_tool],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "agent.invoke(\"what is 2 + 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

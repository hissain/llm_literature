{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
    "\n",
    "    if not api_key or not search_engine_id:\n",
    "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
    "\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\"key\": api_key, \"cx\": search_engine_id, \"q\": query, \"num\": num_results}\n",
    "\n",
    "    response = requests.get(url, params=params)  # type: ignore[arg-type]\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"items\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    return enriched_results\n",
    "\n",
    "\n",
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # # Write results to a file\n",
    "    # with open('arxiv_search_results.json', 'w') as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
    ")\n",
    "\n",
    "\n",
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
    ")\n",
    "\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")\n",
    "\n",
    "\n",
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent], termination_condition=termination\n",
    ")\n",
    "\n",
    "await Console(\n",
    "    team.run_stream(\n",
    "        task=\"Write a literature review on no code tools for building multi agent ai systems\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for Google_Search_Agent/0868cf6e-8324-4eba-aa9d-af8efbf0d3e4\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/qz/jy_v70tj0792_gq7d947v1pw0000gn/T/ipykernel_26570/2364728106.py\", line 51, in create\n",
      "    if msg.get(\"function_call\"):\n",
      "       ^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/pydantic/main.py\", line 891, in __getattr__\n",
      "    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n",
      "AttributeError: 'SystemMessage' object has no attribute 'get'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_single_threaded_agent_runtime.py\", line 505, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_base_agent.py\", line 113, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 48, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 53, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"/Users/hissain/git/github/llm/llm_literature/.venv/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 416, in on_messages_stream\n",
      "    model_result = await self._model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/qz/jy_v70tj0792_gq7d947v1pw0000gn/T/ipykernel_26570/2364728106.py\", line 80, in create\n",
      "    raise Exception(f\"Error in Gemini API call: {str(e)}\")\n",
      "Exception: Error in Gemini API call: 'SystemMessage' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a literature review on no code tools for building multi agent ai systems\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Write a literature review on no code tools for building multi agent ai systems', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "import google.generativeai as genai\n",
    "from typing import List, Optional, Union, Dict\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "class GeminiChatCompletionClient:\n",
    "    def __init__(self, model: str = \"gemini-pro\"):\n",
    "        \"\"\"Initialize Gemini client with API key and model.\"\"\"\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.chat = self.model.start_chat()\n",
    "        \n",
    "        # Complete model_info with all required fields\n",
    "        self.model_info = {\n",
    "            \"name\": model,\n",
    "            \"function_calling\": True,\n",
    "            \"max_tokens\": 30720,\n",
    "            \"context_window\": 30720,\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"vision\": False,  # Added vision field\n",
    "            \"json_mode\": False,  # Added json_mode field\n",
    "            \"seed_required\": False,  # Added seed_required field\n",
    "            \"response_format\": {\"type\": \"text\"},  # Added response_format field\n",
    "            \"supports_functions\": True,  # Added supports_functions field\n",
    "            \"supports_vision\": False,  # Added supports_vision field\n",
    "            \"max_function_calls\": 50  # Added max_function_calls field\n",
    "        }\n",
    "        \n",
    "        # Required configuration attributes\n",
    "        self.config = {\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"timeout\": 60,\n",
    "            \"seed\": None,  # Added seed field\n",
    "            \"response_format\": {\"type\": \"text\"}  # Added response_format field\n",
    "        }\n",
    "\n",
    "    async def create(self, messages: List[Dict[str, str]], **kwargs) -> Dict:\n",
    "        \"\"\"Create a chat completion using Gemini.\"\"\"\n",
    "        try:\n",
    "            # Convert messages to Gemini format\n",
    "            formatted_messages = []\n",
    "            for msg in messages:\n",
    "                # Handle function calls and results\n",
    "                if msg.get(\"function_call\"):\n",
    "                    content = f\"Function call: {json.dumps(msg['function_call'])}\"\n",
    "                elif msg.get(\"role\") == \"function\":\n",
    "                    content = f\"Function result: {msg['content']}\"\n",
    "                else:\n",
    "                    content = msg[\"content\"]\n",
    "                \n",
    "                role = \"user\" if msg[\"role\"] in [\"user\", \"function\"] else \"model\"\n",
    "                formatted_messages.append({\"role\": role, \"parts\": [content]})\n",
    "            \n",
    "            # Get response from Gemini\n",
    "            response = await self.chat.send_message_async(\n",
    "                formatted_messages[-1][\"parts\"][0],\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=kwargs.get(\"temperature\", self.config[\"temperature\"]),\n",
    "                    top_p=kwargs.get(\"top_p\", self.config[\"top_p\"]),\n",
    "                    max_output_tokens=kwargs.get(\"max_tokens\", self.model_info[\"max_output_tokens\"])\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"choices\": [{\n",
    "                    \"message\": {\n",
    "                        \"content\": response.text,\n",
    "                        \"role\": \"assistant\"\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error in Gemini API call: {str(e)}\")\n",
    "\n",
    "    def get_model_info(self):\n",
    "        \"\"\"Return model information.\"\"\"\n",
    "        return self.model_info\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Return configuration.\"\"\"\n",
    "        return self.config\n",
    "\n",
    "# Initialize your tools (assuming google_search_tool and arxiv_search_tool are defined)\n",
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=GeminiChatCompletionClient(model=\"gemini-pro\"),\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=GeminiChatCompletionClient(model=\"gemini-pro\"),\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academic papers.\",\n",
    ")\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=GeminiChatCompletionClient(model=\"gemini-pro\"),\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references. Your response should end with the word 'TERMINATE'\",\n",
    ")\n",
    "\n",
    "# Your existing termination and team setup\n",
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent],\n",
    "    termination_condition=termination\n",
    ")\n",
    "\n",
    "# For notebook environment, use this directly:\n",
    "await Console(\n",
    "    team.run_stream(\n",
    "        task=\"Write a literature review on no code tools for building multi agent ai systems\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
